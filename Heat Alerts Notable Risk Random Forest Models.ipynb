{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn import metrics \n",
    "from scipy.spatial.distance import cdist \n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'F:/Data Analytics-MS!/Integrated Experiential Learn/Week 5 & 6/release/bin'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('F:/Data Analytics-MS!/Integrated Experiential Learn/Week 5 & 6/indicator_pairs_data updated.csv')\n",
    "df2 = pd.read_csv('F:/Data Analytics-MS!/Integrated Experiential Learn/Week 5 & 6/obfuscated_demo_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on='employee_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['alert_type'] != 'Atomic'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Dates'] = pd.to_datetime(df['ge_hire_date']).dt.date\n",
    "df['Time'] = pd.to_datetime(df['ge_hire_date']).dt.time\n",
    "df['year'] = pd.DatetimeIndex(df['Dates']).year\n",
    "df['Tenure'] = df.apply(lambda row: 2020 - row.year, axis = 1) \n",
    "df['year'] = df['year'].fillna(0).astype(int)\n",
    "df['Tenure'] = df['Tenure'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['alert_id_fk', 'insert_date', 'employee_id', 'alert_escalation_date', 'ge_hire_date', 'city', 'state_name', 'country_name', 'alert_category', 'year', 'Time', 'Dates'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting indicator column into multiple columns\n",
    "df[['indicator_pairs', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21']] = df.indicator_pairs.str.split(\"/\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfd = df.copy()\n",
    "dfw = df.copy()\n",
    "dfm = df.copy()\n",
    "dfd = dfd[dfd['alert_type'] != 'Atomic'] \n",
    "dfd = dfd[dfd['alert_type'] == 'Daily_Heat'] \n",
    "dfw = dfw[dfw['alert_type'] != 'Atomic'] \n",
    "dfw = dfw[dfw['alert_type'] == 'Weekly_Heat'] \n",
    "dfm = dfm[dfm['alert_type'] != 'Atomic'] \n",
    "dfm = dfm[dfm['alert_type'] == 'Monthly_Heat'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2907   53]\n",
      " [  84  232]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98      2960\n",
      "          1       0.81      0.73      0.77       316\n",
      "\n",
      "avg / total       0.96      0.96      0.96      3276\n",
      "\n",
      "0.958180708181\n"
     ]
    }
   ],
   "source": [
    "#Target Variable\n",
    "dfd['classification'] = np.where(((dfd['classification'] == 'TP/HIGH') | (dfd['classification'] == 'TP/LOW')), 1, 0)\n",
    "#split dataset in features and target variable\n",
    "feature_cols = ['score', 'owner_name', 'hru', 'person_type', 'person_status', 'alert_type', 'risk_factor', 'Tenure', 'indicator_pairs']\n",
    "X = dfd[feature_cols] # Features\n",
    "y = dfd.classification #Target Variable\n",
    "\n",
    "#One-hot Encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "#Splitting into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "#Training the Algorithm\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958485958486\n",
      "[[2905   55]\n",
      " [  81  235]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943223443223\n",
      "[[2831  129]\n",
      " [  57  259]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935592185592\n",
      "[[2792  168]\n",
      " [  43  273]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.167\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804334554335\n",
      "[[2335  625]\n",
      " [  16  300]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.023\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79884004884\n",
      "[[2317  643]\n",
      " [  16  300]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1967   40]\n",
      " [  60  270]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98      2007\n",
      "          1       0.87      0.82      0.84       330\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2337\n",
      "\n",
      "0.957210098417\n"
     ]
    }
   ],
   "source": [
    "#Target Variable\n",
    "dfw['classification'] = np.where(((dfw['classification'] == 'TP/HIGH') | (dfw['classification'] == 'TP/LOW')), 1, 0)\n",
    "#split dataset in features and target variable\n",
    "feature_cols = ['score', 'owner_name', 'hru', 'person_type', 'person_status', 'alert_type', 'risk_factor', 'Tenure', 'indicator_pairs']\n",
    "X = dfw[feature_cols] # Features\n",
    "y = dfw.classification #Target Variable\n",
    "\n",
    "#One-hot Encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "#Splitting into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "#Training the Algorithm\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957637997433\n",
      "[[1967   40]\n",
      " [  59  271]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95378690629\n",
      "[[1928   79]\n",
      " [  29  301]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "[[1902  105]\n",
      " [  18  312]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.167\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798459563543\n",
      "[[1538  469]\n",
      " [   2  328]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.023\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794608472401\n",
      "[[1529  478]\n",
      " [   2  328]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1995   45]\n",
      " [  49  197]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      2040\n",
      "          1       0.81      0.80      0.81       246\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2286\n",
      "\n",
      "0.958880139983\n"
     ]
    }
   ],
   "source": [
    "#Target Variable\n",
    "dfm['classification'] = np.where(((dfm['classification'] == 'TP/HIGH') | (dfm['classification'] == 'TP/LOW')), 1, 0)\n",
    "#split dataset in features and target variable\n",
    "feature_cols = ['score', 'owner_name', 'hru', 'person_type', 'person_status', 'alert_type', 'risk_factor', 'Tenure', 'indicator_pairs']\n",
    "X = dfm[feature_cols] # Features\n",
    "y = dfm.classification #Target Variable\n",
    "\n",
    "#One-hot Encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "#Splitting into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "#Training the Algorithm\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959755030621\n",
      "[[1992   48]\n",
      " [  44  202]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955380577428\n",
      "[[1962   78]\n",
      " [  24  222]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942694663167\n",
      "[[1928  112]\n",
      " [  19  227]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.167\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790463692038\n",
      "[[1565  475]\n",
      " [   4  242]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.023\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895888014\n",
      "[[1563  477]\n",
      " [   4  242]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "\n",
    "predicted_proba = classifier.predict_proba(X_test)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(accuracy)\n",
    "\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
